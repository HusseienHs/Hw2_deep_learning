ğŸ§  Human Activity Recognition (HAR) â€“ Deep Learning & Machine Learning Project
ğŸ“Œ Overview

This repository contains a complete Human Activity Recognition (HAR) pipeline using sensor data collected from wearable devices.
The goal of the project is to accurately classify human activities such as walking, typing, brushing teeth, and more, using a combination of deep learning, classical machine learning, and feature engineering techniques.

The project explores multiple modeling strategies including CNNs, LSTMs, hybrid CNNâ€“LSTM architectures, Random Forests, and ensemble-based approaches.

ğŸ“‚ Project Structure




ğŸ“‚ Project Structure

This repository is dedicated to the Human Activity Recognition (HAR) project, which aims to classify human activities using sensor data collected from wearable devices.
The project focuses on building and evaluating multiple deep learning and machine learning models to recognize activities such as walking, reading, using a phone, brushing teeth, and more.

ğŸ“ CNN

Contains convolutional neural network implementations used for feature extraction from raw time-series data.

CNN.py â€“ CNN-based feature extractor

cnn_utils.py â€“ Utility functions for CNN models

ğŸ“ LSTM

Implements LSTM-based sequence models and autoencoders.

lstm_autoencoder.py â€“ LSTM autoencoder architecture

lstm_autoencoders_utils.py â€“ Helper functions for LSTM training and inference

ğŸ“ main_models

Contains all main experiments and model pipelines.

cnn_to_rf.ipynb â€“ 3D CNN feature extractor followed by Random Forest

cnn_to_xgb.ipynb â€“ 3D CNN feature extractor with XGBoost

embedding_nn.ipynb â€“ LSTM autoencoder embeddings with neural network classifier

embedding_rf.ipynb â€“ LSTM embeddings with Random Forest

lstm+cnn_rf.ipynb â€“ Combined CNN + LSTM feature extraction with Random Forest

lstm_secret_data.ipynb â€“ 3D CNN trained on extended dataset with missing data recovery

only_1dcnn.ipynb â€“ Pure 1D CNN model

only_cnn.ipynb â€“ Pure 3D CNN model

only_rf.ipynb â€“ Random Forest baseline

only_xgboost.ipynb â€“ XGBoost-based classifier

simple_prob.ipynb â€“ Probability-based baseline using class frequency

ğŸ“ main_utils

Utility scripts used across experiments.

fill_ranges_script.ipynb â€“ Extends missing ranges in training data

generate_graphs.ipynb â€“ Visualization and performance plots

get_all_secret_data.ipynb â€“ Extracts features for hidden test data

get_secret_results.ipynb â€“ Generates final predictions for submission

merge_lstm_results.ipynb â€“ Ensemble method combining multiple LSTM outputs

ğŸ“ models_utils

Core utility modules used throughout the project.

Datasets.py â€“ PyTorch dataset classes

GLOBALS.py â€“ Global configuration and constants

utils.py â€“ Feature extraction and helper utilities

ğŸ“ NN

Neural network utilities and helpers.

NeuralNetwork.py â€“ General neural network architecture

nn_utils.py â€“ Supporting utility functions

ğŸ“ RF_XGB

Classical machine learning models.

RandomForest.py â€“ Random Forest classifier

XGBoost.py â€“ XGBoost model implementation



ğŸ§  Project Components
1ï¸âƒ£ CNN Models

Located in CNN/

Implements 1D and 3D convolutional neural networks.

Used for direct feature extraction from raw time-series sensor data.

Supports both single-sensor and multi-sensor inputs.

2ï¸âƒ£ LSTM Models

Located in LSTM/

Implements LSTM-based autoencoders.

Used for learning temporal representations from sensor sequences.

Can be used as standalone predictors or as feature extractors.

3ï¸âƒ£ Feature Engineering

Located in models_utils/

Extracts statistical features (mean, std, skewness, kurtosis, etc.).

Handles normalization and data preprocessing.

Provides unified Dataset classes for PyTorch pipelines.

4ï¸âƒ£ Classical Machine Learning

Located in RF_XGB/

Random Forest and XGBoost classifiers.

Used on top of extracted features or learned embeddings.

Often used as strong baselines or ensemble components.

5ï¸âƒ£ Experiments & Pipelines

Located in main_models/

End-to-end experiment notebooks.

Includes CNN-only, LSTM-only, hybrid CNN+LSTM, and ensemble models.

Also includes scripts for generating final submission files.

ğŸ“Š Dataset Description

The dataset contains human activity sensor recordings:

Type 1: Smartwatch accelerometer data (x, y, z).

Type 2: Multi-sensor data including acceleration signals.

Each file corresponds to a single activity instance.
The target label represents the performed activity (e.g., walking, typing, washing hands).

ğŸ§ª Model Training & Evaluation

Train/validation split is applied at the subject level.

Models are evaluated using classification accuracy and log loss.

Advanced techniques used:

Feature extraction with CNNs

Sequence modeling with LSTMs

Ensemble learning (RF + NN)

Calibration and probability refinement

ğŸ§  Key Highlights

Hybrid CNNâ€“LSTM architectures outperform standalone models.

Feature-based models (RF/XGBoost) are strong baselines.

Learned representations significantly improve performance.

Modular design enables easy experimentation and extension.

ğŸš€ How to Run

Prepare data inside data/

Run feature extraction or model scripts inside main_models/

Train models and generate predictions

Export results as submission.csv

ğŸ“Œ Notes

All paths are handled via setup_paths.py

GPU acceleration supported (PyTorch)

Designed for reproducibility and scalability
