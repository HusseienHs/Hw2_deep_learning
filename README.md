ğŸ§  Human Activity Recognition (HAR) â€“ Deep Learning & Machine Learning Project
ğŸ“Œ Overview

This repository contains a complete Human Activity Recognition (HAR) pipeline using sensor data collected from wearable devices.
The goal of the project is to accurately classify human activities such as walking, typing, brushing teeth, and more, using a combination of deep learning, classical machine learning, and feature engineering techniques.

The project explores multiple modeling strategies including CNNs, LSTMs, hybrid CNNâ€“LSTM architectures, Random Forests, and ensemble-based approaches.

ğŸ“‚ Project Structure
Source Code/
â”œâ”€â”€ CNN/
â”‚   â”œâ”€â”€ CNN.py
â”‚   â””â”€â”€ cnn_utils.py
â”‚
â”œâ”€â”€ LSTM/
â”‚   â”œâ”€â”€ lstm_autoencoder.py
â”‚   â””â”€â”€ lstm_autoencoders_utils.py
â”‚
â”œâ”€â”€ models_utils/
â”‚   â”œâ”€â”€ Datasets.py
â”‚   â”œâ”€â”€ GLOBALS.py
â”‚   â”œâ”€â”€ utils.py
â”‚
â”œâ”€â”€ RF_XGB/
â”‚   â”œâ”€â”€ RandomForest.py
â”‚   â””â”€â”€ XGBoost.py
â”‚
â”œâ”€â”€ main_models/
â”‚   â”œâ”€â”€ only_cnn.ipynb
â”‚   â”œâ”€â”€ only_1dcnn.ipynb
â”‚   â”œâ”€â”€ lstm+cnn_rf.ipynb
â”‚   â”œâ”€â”€ embedding_rf.ipynb
â”‚   â”œâ”€â”€ lstm_secret_data.ipynb
â”‚   â”œâ”€â”€ only_rf.ipynb
â”‚   â”œâ”€â”€ only_xgboost.ipynb
â”‚   â””â”€â”€ simple_prob.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ unlabeled/
â”‚   â””â”€â”€ sample_submission.csv
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ *.csv
â”‚   â”œâ”€â”€ *.pth
â”‚
â”œâ”€â”€ setup_paths.py
â””â”€â”€ README.md

ğŸ§  Project Components
1ï¸âƒ£ CNN Models

Located in CNN/

Implements 1D and 3D convolutional neural networks.

Used for direct feature extraction from raw time-series sensor data.

Supports both single-sensor and multi-sensor inputs.

2ï¸âƒ£ LSTM Models

Located in LSTM/

Implements LSTM-based autoencoders.

Used for learning temporal representations from sensor sequences.

Can be used as standalone predictors or as feature extractors.

3ï¸âƒ£ Feature Engineering

Located in models_utils/

Extracts statistical features (mean, std, skewness, kurtosis, etc.).

Handles normalization and data preprocessing.

Provides unified Dataset classes for PyTorch pipelines.

4ï¸âƒ£ Classical Machine Learning

Located in RF_XGB/

Random Forest and XGBoost classifiers.

Used on top of extracted features or learned embeddings.

Often used as strong baselines or ensemble components.

5ï¸âƒ£ Experiments & Pipelines

Located in main_models/

End-to-end experiment notebooks.

Includes CNN-only, LSTM-only, hybrid CNN+LSTM, and ensemble models.

Also includes scripts for generating final submission files.

ğŸ“Š Dataset Description

The dataset contains human activity sensor recordings:

Type 1: Smartwatch accelerometer data (x, y, z).

Type 2: Multi-sensor data including acceleration signals.

Each file corresponds to a single activity instance.
The target label represents the performed activity (e.g., walking, typing, washing hands).

ğŸ§ª Model Training & Evaluation

Train/validation split is applied at the subject level.

Models are evaluated using classification accuracy and log loss.

Advanced techniques used:

Feature extraction with CNNs

Sequence modeling with LSTMs

Ensemble learning (RF + NN)

Calibration and probability refinement

ğŸ§  Key Highlights

Hybrid CNNâ€“LSTM architectures outperform standalone models.

Feature-based models (RF/XGBoost) are strong baselines.

Learned representations significantly improve performance.

Modular design enables easy experimentation and extension.

ğŸš€ How to Run

Prepare data inside data/

Run feature extraction or model scripts inside main_models/

Train models and generate predictions

Export results as submission.csv

ğŸ“Œ Notes

All paths are handled via setup_paths.py

GPU acceleration supported (PyTorch)

Designed for reproducibility and scalability
